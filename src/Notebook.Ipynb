{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cbacd23",
   "metadata": {},
   "source": [
    "# Machine Learning Approach to Renewable Energy Dynamics\n",
    "\n",
    "**Auteurs :** Grzegorz Mozdzynski, Hajar Sriri, Jules Chopard  \n",
    "**Date :** Avril 2025\n",
    "\n",
    "This notebook analyzes the determining factors of the share of renewable energies in the final energy consumption of countries. It includes data cleaning, functionality selection, model training (Linear, Lasso, Ridge, Random Forest) and robustness testing (Bootstrap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d56dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. IMPORT LIBRARIES ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcba16a",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Cleaning\n",
    "We load the dataset, clean column names, drop unnecessary geographical variables, and handle missing values in the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff80f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Ensure the file is in the 'data' folder located one level up\n",
    "try:\n",
    "    df = pd.read_csv('../data/global-data-on-sustainable-energy-1.csv')\n",
    "except FileNotFoundError:\n",
    "    # Fallback if the file is in the same folder\n",
    "    df = pd.read_csv('global-data-on-sustainable-energy-1.csv')\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.strip().str.replace('\\n', ' ').str.replace('  ', ' ')\n",
    "\n",
    "# Drop geographical and irrelevant columns\n",
    "columns_to_drop = ['Entity','Year', 'Latitude', 'Longitude', 'Land Area(Km2)', 'Density\\\\n(P/Km2)']\n",
    "df_clean = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Convert to numeric\n",
    "df_clean = df_clean.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop rows where the target is missing\n",
    "target_col = \"Renewable energy share in the total final energy consumption (%)\"\n",
    "df_clean = df_clean.dropna(subset=[target_col])\n",
    "\n",
    "print(f\"Dimensions after initial cleaning: {df_clean.shape}\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058350cb",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (Correlation)\n",
    "We analyze the correlation matrix to identify multicollinearity and see which variables are related to our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feff408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(14, 12))\n",
    "corr_matrix = df_clean.corr()\n",
    "\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', center=0, annot=False, linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b511452",
   "metadata": {},
   "source": [
    "### Dropping Highly Correlated Variables\n",
    "Based on the matrix, we drop certain variables (like electricity from fossil fuels) to avoid redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f56033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop correlated features\n",
    "cols_correlated = ['Access to clean fuels for cooking','Electricity from fossil fuels (TWh)']\n",
    "df_clean = df_clean.drop(columns=cols_correlated)\n",
    "\n",
    "# Show correlations with the target\n",
    "target_corr = corr_matrix[target_col].sort_values(ascending=False)\n",
    "print(\"\\nCorrelation of features with the target:\")\n",
    "print(target_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cc1d00",
   "metadata": {},
   "source": [
    "## 4. Missing Value Imputation (KNN)\n",
    "We use K-Nearest Neighbors imputation (K=3) to fill in missing data while preserving local structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4f4bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = df_clean.drop(columns=[target_col])\n",
    "y = df_clean[target_col]\n",
    "\n",
    "# Temporary standardization for KNN\n",
    "scaler = StandardScaler()\n",
    "X_scaled_temp = scaler.fit_transform(X)\n",
    "\n",
    "# Apply KNNImputer (k=3)\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "X_imputed = imputer.fit_transform(X_scaled_temp)\n",
    "\n",
    "# Create imputed DataFrame\n",
    "X = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "print(\"Imputation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd6cb8c",
   "metadata": {},
   "source": [
    "## 5. Feature Selection (Mixed Stepwise)\n",
    "We use a \"stepwise\" selection (mixing forward and backward) to find the best subset of variables maximizing the R² score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53abb68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = pd.DataFrame(X)\n",
    "lr_fs = LinearRegression()\n",
    "\n",
    "# Apply mixed selection (SFS)\n",
    "sfs = SFS(lr_fs,\n",
    "          k_features='best',\n",
    "          forward=True,\n",
    "          floating=True,\n",
    "          scoring='r2',\n",
    "          cv=5)\n",
    "\n",
    "sfs = sfs.fit(X_temp, y)\n",
    "\n",
    "# List of selected features\n",
    "selected_features = list(sfs.k_feature_names_)\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# Reduce X to selected features\n",
    "X = X_temp[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8b913f",
   "metadata": {},
   "source": [
    "## 6. Model Training and Evaluation\n",
    "We compare here:\n",
    "1.  **Linear Regression**\n",
    "2.  **Lasso (L1)**\n",
    "3.  **Random Forest**\n",
    "\n",
    "We also check the statistical significance of coefficients via OLS (Statsmodels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8067fd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "lr = LinearRegression()\n",
    "lasso = LassoCV(cv=5, random_state=42)\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Training\n",
    "lr.fit(X_train, y_train)\n",
    "lasso.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# OLS Statistical Summary\n",
    "X_train_const = sm.add_constant(X_train.reset_index(drop=True))\n",
    "y_train_reset = y_train.reset_index(drop=True)\n",
    "ols_model = sm.OLS(y_train_reset, X_train_const).fit()\n",
    "print(ols_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a61c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Calculate scores\n",
    "scores = {\n",
    "    'Model': ['Linear Regression', 'Lasso Regression', 'Random Forest'],\n",
    "    'R²': [r2_score(y_test, y_pred_lr), r2_score(y_test, y_pred_lasso), r2_score(y_test, y_pred_rf)],\n",
    "    'RMSE': [\n",
    "        np.sqrt(mean_squared_error(y_test, y_pred_lr)),\n",
    "        np.sqrt(mean_squared_error(y_test, y_pred_lasso)),\n",
    "        np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_scores = pd.DataFrame(scores)\n",
    "print(df_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a478d1",
   "metadata": {},
   "source": [
    "## 7. Ridge Regression and Cross-Validation\n",
    "Adding Ridge regression (L2) and cross-validation to confirm stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593c573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge with built-in CV to find the best alpha\n",
    "ridge = RidgeCV(alphas=np.logspace(-6, 6, 13), cv=5)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "print(f\"Ridge Regression R²: {r2_score(y_test, y_pred_ridge):.4f}\")\n",
    "print(f\"Ridge Regression RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_ridge)):.4f}\")\n",
    "\n",
    "# Cross-Validation (K-Fold) on the training set\n",
    "cv_lr = -np.mean(cross_val_score(lr, X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "cv_ridge = -np.mean(cross_val_score(ridge, X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "cv_lasso = -np.mean(cross_val_score(lasso, X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "\n",
    "print(\"\\n--- Cross-Validation MSE ---\")\n",
    "print(f\"Linear: {cv_lr:.2f}\")\n",
    "print(f\"Ridge:  {cv_ridge:.2f}\")\n",
    "print(f\"Lasso:  {cv_lasso:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab8496b",
   "metadata": {},
   "source": [
    "## 8. Results Visualization\n",
    "Graphical comparison of errors (RMSE) between models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = ['Linear', 'Ridge', 'Lasso', 'Random Forest']\n",
    "rmse_vals = [\n",
    "    np.sqrt(mean_squared_error(y_test, y_pred_lr)),\n",
    "    np.sqrt(mean_squared_error(y_test, y_pred_ridge)),\n",
    "    np.sqrt(mean_squared_error(y_test, y_pred_lasso)),\n",
    "    np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models_list, rmse_vals, color=['skyblue', 'lightblue', 'steelblue', 'green'])\n",
    "plt.title('RMSE Comparison by Model')\n",
    "plt.ylabel('RMSE (lower is better)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6069be6f",
   "metadata": {},
   "source": [
    "## 9. Robustness Analysis (Bootstrap)\n",
    "We use Bootstrap (1000 resamples) to check the stability of the linear model coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4c53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "n_iterations = 1000\n",
    "n_size = int(len(X_train) * 0.8)\n",
    "coefs = np.zeros((n_iterations, X_train.shape[1]))\n",
    "\n",
    "print(\"Running Bootstrap...\")\n",
    "for i in range(n_iterations):\n",
    "    X_res, y_res = resample(X_train, y_train, n_samples=n_size, random_state=i)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_res, y_res)\n",
    "    coefs[i, :] = model.coef_\n",
    "\n",
    "# Results\n",
    "bootstrap_res = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Mean Coeff': np.mean(coefs, axis=0),\n",
    "    'Std Dev': np.std(coefs, axis=0)\n",
    "})\n",
    "\n",
    "print(bootstrap_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d727c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization for a specific feature (e.g., GDP per capita)\n",
    "# Adapt the name if necessary according to automatic selection\n",
    "target_feature = \"gdp_per_capita\"\n",
    "\n",
    "if target_feature in X.columns:\n",
    "    idx = list(X.columns).index(target_feature)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.hist(coefs[:, idx], bins=30, edgecolor='black', color='orange')\n",
    "    plt.title(f'Bootstrap Distribution of Coefficient: {target_feature}')\n",
    "    plt.xlabel('Coefficient Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"The variable '{target_feature}' was not kept during selection.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
